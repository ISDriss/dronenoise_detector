{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from Modelclass import DroneAcoustics\n",
    "from Datasetclass import ImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loding the data this way isn't viable as too many files are opened at the same time.   \n",
    "then we need to open the files only when we need to, so here's the plan:   \n",
    "1- change data_df to be in the form {img_path, label}, (annotation file is ready)\n",
    "2- test if the preprocessed images can all be loaded at the same time (probably not), if it fails: save the preprocessed images in a separate folder \n",
    "3- change the ImageDataset class to behave in a similar manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data\\\\kaggle')\n",
    "labels = []\n",
    "drone_data = []\n",
    "drone_far_data = []\n",
    "noise_data = []\n",
    "\n",
    "def load_data(data_dir, data_list): \n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(data_dir, filename)\n",
    "            img = Image.open(img_path)\n",
    "            data_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1332 drone spectograms.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files: 'C:\\\\Users\\\\Ilian\\\\OneDrive\\\\Documents\\\\GH_Projects\\\\dronenoise_detector\\\\data\\\\kaggle\\\\drone_far\\\\5_2.3163010888610014m_B_S2_D1_092-bebop_003_.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m load_data(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrone\u001b[39m\u001b[38;5;124m'\u001b[39m), drone_data)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(drone_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m drone spectograms.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrone_far\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrone_far_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(drone_far_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m drone_far spectograms.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m load_data(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m'\u001b[39m), noise_data)\n",
      "Cell \u001b[1;32mIn[33], line 11\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_dir, data_list)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     10\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, filename)\n\u001b[1;32m---> 11\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     data_list\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "File \u001b[1;32mc:\\Users\\Ilian\\OneDrive\\Documents\\GH_Projects\\dronenoise_detector\\env\\Lib\\site-packages\\PIL\\Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 24] Too many open files: 'C:\\\\Users\\\\Ilian\\\\OneDrive\\\\Documents\\\\GH_Projects\\\\dronenoise_detector\\\\data\\\\kaggle\\\\drone_far\\\\5_2.3163010888610014m_B_S2_D1_092-bebop_003_.png'"
     ]
    }
   ],
   "source": [
    "# Iterate through all files in the data directory\n",
    "load_data(os.path.join(data_dir, 'drone'), drone_data)\n",
    "print(f\"Loaded {len(drone_data)} drone spectograms.\")\n",
    "\n",
    "load_data(os.path.join(data_dir, 'drone_far'), drone_far_data)\n",
    "print(f\"Loaded {len(drone_far_data)} drone_far spectograms.\")\n",
    "\n",
    "load_data(os.path.join(data_dir, 'noise'), noise_data)\n",
    "print(f\"Loaded {len(noise_data)} noise spectograms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in a dataframe\n",
    "data_df = pd.DataFrame({\n",
    "    'img': drone_data + drone_far_data + noise_data,\n",
    "    'label': ['drone']*len(drone_data) + ['drone_far']*len(drone_far_data) + ['noise']*len(noise_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Testing set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(image_list):\n",
    "    processed_data = []\n",
    "    for img in image_list:\n",
    "        kernel = torch.tensor([[-1, -1, -1],\n",
    "                                [-1, 8, -1],\n",
    "                                [-1, -1, -1]]).float() # define kernel (edge detection)\n",
    "        img = img.convolve(kernel) # apply convolution\n",
    "        img = img.resize((28, 28)) # resize to 28x28\n",
    "        img = img.convert('L') # convert to grayscale\n",
    "        img = torch.tensor(img.getdata()).reshape(1, 28, 28) # reshape to 28x28 tensor\n",
    "        img = img / 255.0 # normalize\n",
    "        img = img.to('cpu') # move to CPU\n",
    "        processed_data.append(img) \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training and testing data\n",
    "train_processed_data = image_preprocessing(train_df['img'])\n",
    "test_processed_data = image_preprocessing(test_df['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DataFrames with the processed data\n",
    "train_df['img'] = train_processed_data\n",
    "test_df['img'] = test_processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "model = DroneAcoustics().to('cpu')    \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders for training and testing\n",
    "train_dataset = ImageDataset(train_df['img'], train_df['label'])\n",
    "test_dataset = ImageDataset(test_df['img'], test_df['label'])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training and testing functions\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to('cpu'), y.to('cpu')\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to('cpu'), y.to('cpu')\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), \"./models/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
